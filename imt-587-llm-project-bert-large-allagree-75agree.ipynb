{"metadata":{"colab":{"provenance":[{"file_id":"1IMQSdk8E86by22W7PG1e_oCWPBV5eAtK","timestamp":1716661577481}],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0870e540599c4d5693376df5ce11c3c3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32deab0fc3f74cd6a746b6750604633d","IPY_MODEL_0c6771201a2547ed93d5e13a2eb501cf","IPY_MODEL_cc9f02447a734e50a0dfbf0e86e28984"],"layout":"IPY_MODEL_fab5895868204eb9948e74f8a4436607"}},"32deab0fc3f74cd6a746b6750604633d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f90afb5a82b54d658acf3f10b8f730f7","placeholder":"​","style":"IPY_MODEL_ec1d445fbfbd45e78ae2ccc663511563","value":"Downloading data: 100%"}},"0c6771201a2547ed93d5e13a2eb501cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b6bc3062ba846d1b4516066e5da4373","max":392286,"min":0,"orientation":"horizontal","style":"IPY_MODEL_465b4a205de94a99898c8ab0b7caa007","value":392286}},"cc9f02447a734e50a0dfbf0e86e28984":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5304321558942a3a47c4a99035a6bc2","placeholder":"​","style":"IPY_MODEL_d714a5a509a24afd89de77bb98ba13a1","value":" 392k/392k [00:00&lt;00:00, 1.60MB/s]"}},"fab5895868204eb9948e74f8a4436607":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f90afb5a82b54d658acf3f10b8f730f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec1d445fbfbd45e78ae2ccc663511563":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b6bc3062ba846d1b4516066e5da4373":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"465b4a205de94a99898c8ab0b7caa007":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5304321558942a3a47c4a99035a6bc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d714a5a509a24afd89de77bb98ba13a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bfb156aaaea4563a4b9ae129862f3bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e9ef607370347318989d4c49b86e4dc","IPY_MODEL_c7b3b1283e3a42cc93960e8a29551445","IPY_MODEL_c9fd03eba84c44f391f857990e787db8"],"layout":"IPY_MODEL_5a3068e8e9f2404cb68654c773905b6b"}},"5e9ef607370347318989d4c49b86e4dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c17e716be74481f8cb1dd32a49c5ad5","placeholder":"​","style":"IPY_MODEL_9155848e8fc84ac4b16290c89594d2b0","value":"Generating train split: 100%"}},"c7b3b1283e3a42cc93960e8a29551445":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11abefa471214302b8493db3e8efce73","max":4846,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7136d1bd7fcf44f18d06e40954fd820c","value":4846}},"c9fd03eba84c44f391f857990e787db8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49278b9fb03949bd99e833fe1bd7793a","placeholder":"​","style":"IPY_MODEL_8bc01fabca11404e9f2e206b9dd4a3be","value":" 4846/4846 [00:00&lt;00:00, 78849.23 examples/s]"}},"5a3068e8e9f2404cb68654c773905b6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c17e716be74481f8cb1dd32a49c5ad5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9155848e8fc84ac4b16290c89594d2b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11abefa471214302b8493db3e8efce73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7136d1bd7fcf44f18d06e40954fd820c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49278b9fb03949bd99e833fe1bd7793a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bc01fabca11404e9f2e206b9dd4a3be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **FINANCE NEWS - SENTIMENT ANALYSIS**\n\n**Financial PhraseBank:** A dataset containing financial news sentences annotated with sentiment labels.\n\n**sentences_allagree:** A specific subset of this dataset where every annotator provided the same sentiment label for each sentence. There are 2264 entries in this dataset.\n\nFor the sentences_allagree subset, the labels are encoded as follows:\n\n\n*   0: Negative sentiment\n*   1: Neutral sentiment\n*   2: Positive sentiment","metadata":{"_uuid":"6b065dd9-4264-4ffd-b435-3a2c2c1c9989","_cell_guid":"04788a66-3a55-452b-8ea8-53d49204f260","id":"-Va1qc9Kr4mS","trusted":true}},{"cell_type":"code","source":"!pip install datasets","metadata":{"_uuid":"27320eb0-2275-4e89-9471-6a8828ade9df","_cell_guid":"8e4ae9a2-0b68-4d34-88c0-88a6ecf45bfa","collapsed":false,"id":"9KO5GgqKv9Qa","executionInfo":{"status":"ok","timestamp":1716423513802,"user_tz":420,"elapsed":22124,"user":{"displayName":"YONGXU Sun","userId":"01161063662974634604"}},"outputId":"6ffd08ce-5894-4d62-e16f-41ca244344b3","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define the directory to be cleared\noutput_dir = '/kaggle/working/'\n\n# Function to clear a directory\ndef clear_directory(directory):\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        try:\n            if os.path.isfile(file_path) or os.path.islink(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n        except Exception as e:\n            print(f'Failed to delete {file_path}. Reason: {e}')\n\n# Clear the output directory\nclear_directory(output_dir)\n\n# Verify the directory is empty\nprint(\"Directory contents after clearing:\", os.listdir(output_dir))\n\nimport torch\n\n# Clear CUDA cache\ntorch.cuda.empty_cache()\n\nprint(\"CUDA cache cleared.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T23:42:03.202380Z","iopub.execute_input":"2024-05-25T23:42:03.203003Z","iopub.status.idle":"2024-05-25T23:42:04.830193Z","shell.execute_reply.started":"2024-05-25T23:42:03.202968Z","shell.execute_reply":"2024-05-25T23:42:04.829216Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Directory contents after clearing: []\nCUDA cache cleared.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nfrom torch.nn import CrossEntropyLoss\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport numpy as np\nfrom datasets import load_dataset\nimport re\nfrom bs4 import BeautifulSoup\nimport html\nimport random\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\ndevice = 'cuda'\n\n\n# Define a directory to save the model in Google Drive\noutput_dir = '//kaggle/working/'\n\n# Create output directory if needed\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)","metadata":{"_uuid":"f85539be-15f4-4fba-897b-b1b294157fae","_cell_guid":"73e74896-50e0-456e-a2f0-7667a82d35bd","collapsed":false,"id":"kPVP4S9pr4Hm","executionInfo":{"status":"ok","timestamp":1716423544472,"user_tz":420,"elapsed":30674,"user":{"displayName":"YONGXU Sun","userId":"01161063662974634604"}},"outputId":"332099a9-81df-4e5e-8f03-b0549c4d1d29","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-25T23:42:05.732513Z","iopub.execute_input":"2024-05-25T23:42:05.733053Z","iopub.status.idle":"2024-05-25T23:42:08.829736Z","shell.execute_reply.started":"2024-05-25T23:42:05.733020Z","shell.execute_reply":"2024-05-25T23:42:08.828916Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndataset = load_dataset('financial_phrasebank', 'sentences_allagree')\ndf = pd.DataFrame(dataset['train'])","metadata":{"_uuid":"de326bfd-d4bb-4ee4-a39c-30bd0ca4c8fd","_cell_guid":"bab44c3c-959b-4fb3-88c9-337076ab720a","collapsed":false,"id":"RpIoQvL-wFgF","executionInfo":{"status":"ok","timestamp":1716423564096,"user_tz":420,"elapsed":3532,"user":{"displayName":"YONGXU Sun","userId":"01161063662974634604"}},"outputId":"b2381332-6d5d-4adb-bb36-b89b92dcb961","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load dataset\ndataset = load_dataset('financial_phrasebank', 'sentences_75agree')\ndf = pd.DataFrame(dataset['train'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"_uuid":"ed2d946c-306d-41dd-8451-c6ce6199939d","_cell_guid":"da4a141c-7b70-4a70-b52d-7d5e6949e3f2","collapsed":false,"id":"LHqm_1lhy5_B","executionInfo":{"status":"ok","timestamp":1716423569237,"user_tz":420,"elapsed":154,"user":{"displayName":"YONGXU Sun","userId":"01161063662974634604"}},"outputId":"28295167-f213-44aa-85aa-1d58bafa9bda","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract model input and output\ntexts = dataset['train']['sentence']\nlabels = dataset['train']['label']\n\n# Split the dataset into 90% training and 10% validation\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)","metadata":{"_uuid":"fcc9f94d-3bf0-4d26-9a64-b19a96a30064","_cell_guid":"5a27ad6b-1d25-4fe9-b0af-49c0a17b4f9b","collapsed":false,"id":"HYpVa8UR2m_E","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Load the stored model**","metadata":{"_uuid":"10d2e922-f001-425a-9423-56dfc68a3b23","_cell_guid":"55dc574b-48d1-48cb-bf9c-3fc4f75dd23d","id":"55trRxJ6HyyI","trusted":true}},{"cell_type":"code","source":"# Load the saved model and tokenizer\nprint(\"Loading model from %s\" % output_dir)\n\nmodel = BertForSequenceClassification.from_pretrained(output_dir)\ntokenizer = BertTokenizer.from_pretrained(output_dir)\n\n# Move the model to the appropriate device\nmodel = model.to(device)","metadata":{"_uuid":"45f767f9-ecf2-49cf-bf26-8bdd04eb0a0c","_cell_guid":"4fbfa607-adce-4304-a613-3f6981624a03","collapsed":false,"id":"cB_2nytfHw-A","executionInfo":{"status":"error","timestamp":1716423630266,"user_tz":420,"elapsed":192,"user":{"displayName":"YONGXU Sun","userId":"01161063662974634604"}},"outputId":"b97c04ac-7154-4416-a970-98737f758022","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Create a new model and train**","metadata":{"_uuid":"cce3afb5-0256-4f1a-87d0-464efad1c9f4","_cell_guid":"0398fbdf-e34a-480a-95b8-db8c9367057d","id":"AhbNqT_NH3gB","trusted":true}},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n\nmodel = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=3)\nmodel = model.to(device)\n\noptimizer = AdamW(model.parameters(), lr=1e-5)","metadata":{"_uuid":"893f1a11-9efb-4262-9137-b887ea50993d","_cell_guid":"58ae25e5-2051-42e7-9514-71a84845b003","collapsed":false,"id":"NW0FggEN3X_T","executionInfo":{"status":"ok","timestamp":1716410671855,"user_tz":420,"elapsed":2155,"user":{"displayName":"Sheel Sanghvi","userId":"03454583346489679413"}},"outputId":"f8817ffd-923c-4010-b82c-3d022e970f33","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize input\nprint('Tokenizing the input...')\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='pt')\n\n#Convert to tensors\nprint('Converting to tensors...')\ntrain_inputs = train_encodings['input_ids'].to(device)\ntrain_masks = train_encodings['attention_mask'].to(device)\ntrain_outputs = torch.tensor(train_labels).to(device)\n\n#Create DataLoader\nprint('Loading the data...')\ntrain_dataset = TensorDataset(train_inputs, train_masks, train_outputs)\ntrain_sampler = RandomSampler(train_dataset)\ntrain_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=32)","metadata":{"_uuid":"0460be8d-58cb-4362-893f-1b1ac07173a3","_cell_guid":"f66381b7-f9f2-4a46-8a3a-dd2504e48fd5","collapsed":false,"id":"hJgqlGmZ3c9X","executionInfo":{"status":"ok","timestamp":1716410674076,"user_tz":420,"elapsed":2222,"user":{"displayName":"Sheel Sanghvi","userId":"03454583346489679413"}},"outputId":"1d3d01c7-d072-4af5-9f66-60963f8663f4","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training loop\nprint('Training...')\nmodel.train()\nfor epoch in range(30):\n  total_loss = 0\n  for step, batch in enumerate(train_dataloader):\n    b_input_ids, b_input_mask, b_labels = batch\n    optimizer.zero_grad()\n    outputs = model(b_input_ids, labels=b_labels)\n    loss = outputs.loss\n    loss.backward()\n    optimizer.step()\n    total_loss += loss.item()\n  print(f\"Epoch {epoch + 1} --> Total Loss: {total_loss}\")","metadata":{"_uuid":"a74149b4-bc3e-4373-8118-704a99c0c419","_cell_guid":"91632117-8765-43a7-be5d-d232138b1096","collapsed":false,"id":"LfgZIbDk3jLG","executionInfo":{"status":"ok","timestamp":1716411088781,"user_tz":420,"elapsed":414707,"user":{"displayName":"Sheel Sanghvi","userId":"03454583346489679413"}},"outputId":"9930e60c-e306-4daf-a78d-ce9a3ae206f3","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a directory to save the model in Google Drive\noutput_dir = '//kaggle/working/'\n\n# Create output directory if needed\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# Save a trained model, configuration and tokenizer\nprint(\"Saving model to %s\" % output_dir)\n\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)","metadata":{"_uuid":"9dc40d85-4e85-4eb2-8afb-4af19901ffbf","_cell_guid":"fd2e99bb-9593-42a2-89a2-bdaa70f55d1f","collapsed":false,"id":"Rb6OdNu4_xk2","executionInfo":{"status":"ok","timestamp":1716412191905,"user_tz":420,"elapsed":1847,"user":{"displayName":"Sheel Sanghvi","userId":"03454583346489679413"}},"outputId":"cd296306-9cf5-4e15-c854-99d60ae42ef1","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **TESTING THE MODEL WITH THE VALIDATION DATA**","metadata":{"_uuid":"049c3460-e14b-40c9-9ece-5aaac420c6d4","_cell_guid":"2927019c-ebbf-4c95-9060-24000639f206","id":"wjO5nQDQAKDd","trusted":true}},{"cell_type":"code","source":"# Tokenize output\nprint('Tokenizing the output...')\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors='pt')\n\n#Convert to tensors\nprint('Converting to tensors...')\nval_inputs = val_encodings['input_ids'].to(device)\nval_masks = val_encodings['attention_mask'].to(device)\nval_outputs = torch.tensor(val_labels).to(device)\n\n#Create DataLoader\nprint('Loading the data...')\nval_dataset = TensorDataset(val_inputs, val_masks, val_outputs)\nval_sampler = SequentialSampler(val_dataset)\nval_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=32)","metadata":{"_uuid":"00b2ea02-2335-47d0-8d20-da966c1a7dd0","_cell_guid":"2ef2de5f-b057-4294-8f52-ec2fda27d2f1","collapsed":false,"id":"Cr5PPXaw_oY_","executionInfo":{"status":"ok","timestamp":1716412286375,"user_tz":420,"elapsed":1135,"user":{"displayName":"Sheel Sanghvi","userId":"03454583346489679413"}},"outputId":"41847b34-11fc-48b1-8410-58be5891abb5","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Evaluating...')\nmodel.eval()\nval_pred_labels, val_true_labels = [], []\nwith torch.no_grad():\n    for batch in val_dataloader:\n        b_input_ids, b_input_mask, b_labels = batch\n        outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n        logits = outputs.logits\n        val_pred_labels.extend(torch.argmax(logits, dim=1).cpu().numpy())\n        val_true_labels.extend(b_labels.cpu().numpy())\n\naccuracy = accuracy_score(val_true_labels, val_pred_labels)\nprint(f'Validation Accuracy: {accuracy}')\n\n","metadata":{"_uuid":"a3c86eed-3906-4fe2-8678-803bf6d56725","_cell_guid":"1ca69d2a-08bf-478d-b7bb-4709008baea8","collapsed":false,"id":"WB4yjG6a_gtm","executionInfo":{"status":"ok","timestamp":1716412287820,"user_tz":420,"elapsed":772,"user":{"displayName":"Sheel Sanghvi","userId":"03454583346489679413"}},"outputId":"0b7a1b99-1d69-47ac-e815-a7c24094b490","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model over 30 loops\nnum_loops = 30\naccuracies = []\n\nfor _ in range(num_loops):\n    model.eval()\n    val_pred_labels, val_true_labels = [], []\n\n    with torch.no_grad():\n        for batch in val_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n            logits = outputs.logits\n            val_pred_labels.extend(torch.argmax(logits, dim=1).cpu().numpy())\n            val_true_labels.extend(b_labels.cpu().numpy())\n\n    # Calculate accuracy for this loop\n    accuracy = accuracy_score(val_true_labels, val_pred_labels)\n    accuracies.append(accuracy)\n\n# Calculate the average accuracy\naverage_accuracy = np.mean(accuracies)\nprint(f'Average Validation Accuracy over {num_loops} loops: {average_accuracy}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline Testing (bert-large-uncased)","metadata":{}},{"cell_type":"markdown","source":"Clear workspace/cache","metadata":{}},{"cell_type":"code","source":"#clearing cache & workspace before each run\n\nimport os\nimport shutil\n\n# Define the directory to be cleared\noutput_dir = '/kaggle/working/'\n\n# Function to clear a directory\ndef clear_directory(directory):\n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        try:\n            if os.path.isfile(file_path) or os.path.islink(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n        except Exception as e:\n            print(f'Failed to delete {file_path}. Reason: {e}')\n\n# Clear the output directory\nclear_directory(output_dir)\n\n# Verify the directory is empty\nprint(\"Directory contents after clearing:\", os.listdir(output_dir))\n\nimport torch\n\n# Clear CUDA cache\ntorch.cuda.empty_cache()\n\nprint(\"CUDA cache cleared.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy loop","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader, SequentialSampler, TensorDataset\nimport torch\nfrom datasets import load_dataset\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Load dataset\ndataset = load_dataset('financial_phrasebank', 'sentences_allagree')\ntexts = dataset['train']['sentence']\nlabels = dataset['train']['label']\n\n# Split the dataset into 90% training and 10% validation\nfrom sklearn.model_selection import train_test_split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)\n\n# Load the pre-trained BERT model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=3)\nmodel = model.to(device)\n\n# Tokenize the validation data\nval_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors='pt')\n\n# Convert to tensors\nval_inputs = val_encodings['input_ids'].to(device)\nval_masks = val_encodings['attention_mask'].to(device)\nval_outputs = torch.tensor(val_labels).to(device)\n\n# Create DataLoader\nval_dataset = TensorDataset(val_inputs, val_masks, val_outputs)\nval_sampler = SequentialSampler(val_dataset)\nval_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=32)\n\n# Evaluate the model over 30 loops\nnum_loops = 30\naccuracies = []\n\nfor _ in range(num_loops):\n    model.eval()\n    val_pred_labels, val_true_labels = [], []\n\n    with torch.no_grad():\n        for batch in val_dataloader:\n            b_input_ids, b_input_mask, b_labels = batch\n            outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n            logits = outputs.logits\n            val_pred_labels.extend(torch.argmax(logits, dim=1).cpu().numpy())\n            val_true_labels.extend(b_labels.cpu().numpy())\n\n    # Calculate accuracy for this loop\n    accuracy = accuracy_score(val_true_labels, val_pred_labels)\n    accuracies.append(accuracy)\n\n# Calculate the average accuracy\naverage_accuracy = np.mean(accuracies)\nprint(f'Average Validation Accuracy over {num_loops} loops: {average_accuracy}')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Combined Function","metadata":{}},{"cell_type":"markdown","source":"Combined Baseline","metadata":{}},{"cell_type":"code","source":"def bert_large_test(data):\n  dataset=load_dataset('financial_phrasebank', 'sentences_75agree')\n \n  # Extract model input and output\n  texts = dataset['train']['sentence']\n  labels = dataset['train']['label']\n \n  # Split the dataset into 90% training and 10% validation\n  train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)\n \n  tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n \n  model = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=3)\n  model = model.to(device)\n \n  optimizer = AdamW(model.parameters(), lr=1e-5)\n \n  # Evaluation\n  model.eval()\n  val_pred_labels, val_true_labels = [], []\n  with torch.no_grad():\n      for batch in val_dataloader:\n          b_input_ids, b_input_mask, b_labels = batch\n          outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n          logits = outputs.logits\n          val_pred_labels.extend(torch.argmax(logits, dim=1).cpu().numpy())\n          val_true_labels.extend(b_labels.cpu().numpy())\n \n  # Find misclassified examples\n  misclassified_examples = []\n  for i in range(len(val_true_labels)):\n      if val_true_labels[i] != val_pred_labels[i]:\n          misclassified_examples.append((val_texts[i], val_true_labels[i], val_pred_labels[i]))\n \n  # Print some misclassified examples\n  print(\"Misclassified examples:\")\n  for text, true_label, pred_label in misclassified_examples[:5]:\n      print(f\"Text: {text}\")\n      print(f\"True label: {true_label}\")\n      print(f\"Predicted label: {pred_label}\")\n  return accuracy_score(val_true_labels, val_pred_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Combined Training","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_large_test(data):\n  dataset=load_dataset('financial_phrasebank', data)\n \n  # Extract model input and output\n  texts = dataset['train']['sentence']\n  labels = dataset['train']['label']\n \n  # Split the dataset into 90% training and 10% validation\n  train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.1, random_state=42)\n \n  tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n \n  model = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=3)\n  model = model.to(device)\n \n  optimizer = AdamW(model.parameters(), lr=1e-5)\n \n  # Tokenize input\n  train_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='pt')\n \n  #Convert to tensors\n  train_inputs = train_encodings['input_ids'].to(device)\n  train_masks = train_encodings['attention_mask'].to(device)\n  train_outputs = torch.tensor(train_labels).to(device)\n \n  #Create DataLoader\n  train_dataset = TensorDataset(train_inputs, train_masks, train_outputs)\n  train_sampler = RandomSampler(train_dataset)\n  train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=32)\n \n  #Training loop\n  model.train()\n  for epoch in range(30):\n    total_loss = 0\n    for step, batch in enumerate(train_dataloader):\n      b_input_ids, b_input_mask, b_labels = batch\n      optimizer.zero_grad()\n      outputs = model(b_input_ids, labels=b_labels)\n      loss = outputs.loss\n      loss.backward()\n      optimizer.step()\n      total_loss += loss.item()\n    print(f\"Epoch {epoch + 1} --> Total Loss: {total_loss}\")\n \n    # Tokenize output\n  val_encodings = tokenizer(val_texts, truncation=True, padding=True, return_tensors='pt')\n \n  #Convert to tensors\n  val_inputs = val_encodings['input_ids'].to(device)\n  val_masks = val_encodings['attention_mask'].to(device)\n  val_outputs = torch.tensor(val_labels).to(device)\n \n  #Create DataLoader\n  val_dataset = TensorDataset(val_inputs, val_masks, val_outputs)\n  val_sampler = SequentialSampler(val_dataset)\n  val_dataloader = DataLoader(val_dataset, sampler=val_sampler, batch_size=32)\n \n  # Evaluation\n  model.eval()\n  val_pred_labels, val_true_labels = [], []\n  with torch.no_grad():\n      for batch in val_dataloader:\n          b_input_ids, b_input_mask, b_labels = batch\n          outputs = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n          logits = outputs.logits\n          val_pred_labels.extend(torch.argmax(logits, dim=1).cpu().numpy())\n          val_true_labels.extend(b_labels.cpu().numpy())\n \n  # Find misclassified examples\n  misclassified_examples = []\n  for i in range(len(val_true_labels)):\n      if val_true_labels[i] != val_pred_labels[i]:\n          misclassified_examples.append((val_texts[i], val_true_labels[i], val_pred_labels[i]))\n \n  # Print some misclassified examples\n  print(\"Misclassified examples:\")\n  for text, true_label, pred_label in misclassified_examples[:5]:\n      print(f\"Text: {text}\")\n      print(f\"True label: {true_label}\")\n      print(f\"Predicted label: {pred_label}\")\n  return accuracy_score(val_true_labels, val_pred_labels)","metadata":{"_uuid":"7300feae-ab46-42ef-a7f0-b7f2ef0c8bb0","_cell_guid":"5903b8cc-9371-4f35-82b5-a0b6df64794b","collapsed":false,"id":"DS4Q_4JoAFut","executionInfo":{"status":"ok","timestamp":1716412291994,"user_tz":420,"elapsed":437,"user":{"displayName":"Sheel Sanghvi","userId":"03454583346489679413"}},"outputId":"f6463440-7131-47d7-e093-abe79fa5f665","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-05-25T23:42:16.214725Z","iopub.execute_input":"2024-05-25T23:42:16.215317Z","iopub.status.idle":"2024-05-25T23:42:16.231845Z","shell.execute_reply.started":"2024-05-25T23:42:16.215286Z","shell.execute_reply":"2024-05-25T23:42:16.230882Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"data = 'sentences_75agree'\n# Call the bert_large_test function\nbert_large_test(data)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T23:43:19.338486Z","iopub.execute_input":"2024-05-25T23:43:19.339253Z","iopub.status.idle":"2024-05-26T00:51:38.540612Z","shell.execute_reply.started":"2024-05-25T23:43:19.339218Z","shell.execute_reply":"2024-05-26T00:51:38.539693Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for financial_phrasebank contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/financial_phrasebank\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 --> Total Loss: 84.81674826145172\nEpoch 2 --> Total Loss: 57.49486793577671\nEpoch 3 --> Total Loss: 31.330335520207882\nEpoch 4 --> Total Loss: 21.327181842178106\nEpoch 5 --> Total Loss: 12.293487310409546\nEpoch 6 --> Total Loss: 8.036630846560001\nEpoch 7 --> Total Loss: 5.304461032152176\nEpoch 8 --> Total Loss: 4.985310522606596\nEpoch 9 --> Total Loss: 2.336323172552511\nEpoch 10 --> Total Loss: 3.396993040689267\nEpoch 11 --> Total Loss: 3.1719777225516737\nEpoch 12 --> Total Loss: 1.7226171565125696\nEpoch 13 --> Total Loss: 0.7230826548184268\nEpoch 14 --> Total Loss: 0.7050131310825236\nEpoch 15 --> Total Loss: 3.035689419368282\nEpoch 16 --> Total Loss: 1.754714650567621\nEpoch 17 --> Total Loss: 0.5950087097007781\nEpoch 18 --> Total Loss: 1.0077748318435624\nEpoch 19 --> Total Loss: 0.4295839100959711\nEpoch 20 --> Total Loss: 0.47974305824027397\nEpoch 21 --> Total Loss: 0.3834576520312112\nEpoch 22 --> Total Loss: 0.06556349530001171\nEpoch 23 --> Total Loss: 0.04994536090816837\nEpoch 24 --> Total Loss: 0.0990109807025874\nEpoch 25 --> Total Loss: 0.4568091175024165\nEpoch 26 --> Total Loss: 0.4499944832059555\nEpoch 27 --> Total Loss: 0.07807231621700339\nEpoch 28 --> Total Loss: 0.3795232542324811\nEpoch 29 --> Total Loss: 1.8393008931307122\nEpoch 30 --> Total Loss: 2.479577712889295\nMisclassified examples:\nText: Of the price , Kesko 's share is 10 mln euro $ 15.5 mln and it will recognize a gain of 4.0 mln euro $ 6.2 mln on the disposal which will be included in the result for the second quarter of 2008 .\nTrue label: 2\nPredicted label: 1\nText: Bilfinger investors cheered the agreement , pushing shares up 7 % , or & euro ; 3.30 , to & euro ; 50.29 , in afternoon trade .\nTrue label: 2\nPredicted label: 1\nText: The company is also featured in the Ethibel Pioneer Investment Register and included in Innovest 's Global 100 list of the world 's most sustainable corporations .\nTrue label: 2\nPredicted label: 1\nText: The announced restructuring will significantly decrease the Company 's indebtedness .\nTrue label: 2\nPredicted label: 1\nText: Industry Investment is very interested in Glaston 's solar energy projects .\nTrue label: 2\nPredicted label: 1\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0.8554913294797688"},"metadata":{}}]},{"cell_type":"markdown","source":"### **TESTING THE DATA WITH CUSTOM DATA**","metadata":{"_uuid":"f19397d4-b3bd-46a3-9dd7-be83e53a3848","_cell_guid":"a5e813e0-9b51-4891-804a-557ab58f7487","id":"WUhnR7pRDG3T","trusted":true}},{"cell_type":"code","source":"# Function to predict labels for custom inputs\ndef predict_custom_sentences(sentences, model, tokenizer, device):\n    # Tokenize the input sentences\n    encodings = tokenizer(sentences, truncation=True, padding=True, return_tensors='pt')\n\n    # Move the encodings to the appropriate device\n    input_ids = encodings['input_ids'].to(device)\n    attention_mask = encodings['attention_mask'].to(device)\n\n    # Put the model in evaluation mode\n    model.eval()\n\n    # Make predictions\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n\n    # Get the predicted labels\n    preds = torch.argmax(logits, dim=1).cpu().numpy()\n\n    return preds\n\n# Function to map label integers to words\ndef label_to_word(label):\n    label_dict = {0: 'negative', 1: 'neutral', 2: 'positive'}\n    return label_dict.get(label, 'unknown')","metadata":{"_uuid":"d36adacd-5c81-4e0c-ae75-8f54815a7cdc","_cell_guid":"71b3c9bb-db7a-4695-8fe8-945f99801d66","collapsed":false,"id":"_E393IrbDJ2a","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example usage\ncustom_sentences = [\n    \"The company reported a significant increase in revenue.\",\n    \"There are concerns about the sustainability of the growth.\",\n    \"The new product launch has been very successful.\",\n    \"Despite a challenging market environment, the company's strategic decisions have led to considerable improvements in their financial performance.\",\n    \"The recent partnership with a major tech firm is expected to drive innovation and increase market share in the coming years.\",\n    \"My profit last year was $10. This year it is $8.\",\n    \"My profit last year was $10. This year it is reduced to $8\"\n]\n\n# Ensure the model and tokenizer are already loaded and configured\npredicted_labels = predict_custom_sentences(custom_sentences, model, tokenizer, device)\n\n# Map predicted labels to words\npredicted_labels_words = [label_to_word(label) for label in predicted_labels]\n\n# Create a DataFrame\ndf_predictions = pd.DataFrame({\n    'Financial News': custom_sentences,\n    'Predicted Label': predicted_labels_words\n})\n\n# Display the DataFrame\nprint(df_predictions)","metadata":{"_uuid":"473b6431-629f-4dd1-8c75-a8c9730e1127","_cell_guid":"15e3860f-d860-4753-a068-d7db82eb873d","collapsed":false,"id":"uZVYk_KCEI4w","executionInfo":{"status":"ok","timestamp":1716412273841,"user_tz":420,"elapsed":2,"user":{"displayName":"Sheel Sanghvi","userId":"03454583346489679413"}},"outputId":"e5e1480b-023e-4dcf-85ad-c595db90c9ba","jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"BERT and other transformer-based models are pre-trained on large corpora and are adept at capturing the nuances of language, but they aren't explicitly designed to handle numerical reasoning or arithmetic operations. When dealing with sentences containing numerical data, the model might rely more on the surrounding context and words rather than understanding the numerical relationships.","metadata":{"_uuid":"2ce53547-9f28-4a11-819d-8749a34b82e8","_cell_guid":"9e2d4dec-b4e4-438e-858d-a2a3460e0921","id":"AjW8DI_JGh77","trusted":true}}]}